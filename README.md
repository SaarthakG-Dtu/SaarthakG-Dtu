<!-- ================= HEADER ================= -->

<h1 align="center">ğŸ‘¨â€ğŸ’» Saarthak Gupta</h1>
<h3 align="center">ğŸ§  Aspiring AI Researcher | ğŸ‘ï¸ Computer Vision | ğŸ¤– Multimodal AI | ğŸŒ World Modelling</h3>

<p align="center">
  <img src="https://readme-typing-svg.demolab.com/?lines=Aspiring+AI+Researcher;Computer+Vision+%7C+Multimodal+Perception;Building+Real-World+Intelligent+Systems;Exploring+AI+Reasoning+and+World+Models&center=true&width=900&height=45">
</p>

<p align="center">
  <img src="https://komarev.com/ghpvc/?username=SaarthakG-Dtu&label=Profile+Views&style=for-the-badge&color=0A66C2"/>
</p>

<!-- ================= HERO GIF ================= -->

<p align="center">
  <img src="https://media.giphy.com/media/qgQUggAC3Pfv687qPC/giphy.gif" width="480"/>
</p>

---

# ğŸŒ± About Me

ğŸ“ B.Tech in Mathematics & Computing @ Delhi Technological University (DTU)
ğŸ”¬ Deeply interested in the intersection of **Computer Vision, Multimodal AI, and Intelligent Perception Systems**

I am passionate about building AI systems that can
âœ¨ perceive the real world
ğŸ§© reason over complex environments
ğŸŒ and move towards true world modelling

Currently exploring research directions in perception-driven AI and real-world intelligent systems.

---

# ğŸš Research Exposure & Learning Journey

## ğŸ›°ï¸ UAS-DTU | Software Team (DARPA TRIAGE Challenge)

<p align="center">
  <img src="https://media.giphy.com/media/26tn33aiTi1jkl6H6/giphy.gif" width="380"/>
</p>

ğŸŒŸ Contributed to a real-time **multimodal perception system** for medical triaging
ğŸ§  Explored sensor fusion, motion understanding, and perception pipelines
ğŸ‘ï¸ Worked with vision + depth based modelling approaches
ğŸ“Š Experimented with temporal modelling using LSTM for motion analysis

This experience strengthened my interest in **real-world AI systems and multimodal perception research**.

---

# ğŸ”¬ Research Interests (What I Aim to Work On)

ğŸ‘ï¸ Computer Vision & Scene Understanding
ğŸ¤– Multimodal Models (Vision + Sensor Fusion)
ğŸ§  AI Reasoning & World Models
ğŸ›°ï¸ Autonomous & Aerial Perception Systems
ğŸ“¡ Real-Time Intelligent Systems

---

# ğŸ› ï¸ Technical Stack

## ğŸ’» Languages

ğŸ Python (Primary)
âš™ï¸ C++ (Foundational)

---

## ğŸ¤– AI / Deep Learning

<p>
  <img src="https://img.shields.io/badge/PyTorch-FF6F00?style=for-the-badge&logo=pytorch&logoColor=white"/>
  <img src="https://img.shields.io/badge/HuggingFace-FFD21E?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Deep_Learning-8A2BE2?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/CNNs-FF1493?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/RNNs-20B2AA?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/UNet-008080?style=for-the-badge"/>
</p>

---

## ğŸ‘ï¸ Computer Vision & Perception

<p>
  <img src="https://img.shields.io/badge/OpenCV-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white"/>
  <img src="https://img.shields.io/badge/YOLOv8-000000?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Semantic_Segmentation-FF8C00?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Image_Processing-4682B4?style=for-the-badge"/>
</p>

---

## ğŸ“Š Data & Core Libraries

<p>
  <img src="https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy"/>
  <img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas"/>
  <img src="https://img.shields.io/badge/Scikit_Learn-F7931E?style=for-the-badge&logo=scikit-learn"/>
</p>

---

# ğŸš€ Projects & Explorations

## ğŸ›°ï¸ Semantic Segmentation on Aerial Drone Images

<p align="center">
  <img src="https://media.giphy.com/media/3o7btPCcdNniyf0ArS/giphy.gif" width="420"/>
</p>

ğŸ”¹ Built UNet with transfer learning backbone using PyTorch
ğŸ”¹ Designed patching & reconstruction pipeline for high-resolution aerial data
ğŸ”¹ Focused on detecting small objects in large-scale imagery
ğŸ”¹ Optimized training with OneCycleLR & AdamW

---

## ğŸ Vision-Based Fruit Counting System

ğŸ”¸ Dual-view detection using YOLOv8 + OpenCV
ğŸ”¸ Homography transformation with ORB feature matching
ğŸ”¸ Color-aware detection using HSV masking
ğŸ”¸ Spatial matching using Euclidean distance logic

---

## ğŸ§© Multimodal Perception Experiments

ğŸ”¹ Sensor fusion (Vision + Depth + Motion signals)
ğŸ”¹ Temporal modelling using LSTM architectures
ğŸ”¹ Dense pixel tracking & motion feature engineering
ğŸ”¹ Real-time perception pipeline exploration

---

# ğŸ“ˆ GitHub Analytics

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=SaarthakG-Dtu&show_icons=true&theme=tokyonight&hide_border=true" height="165"/>
  <img src="https://github-readme-streak-stats.herokuapp.com/?user=SaarthakG-Dtu&theme=tokyonight&hide_border=true" height="165"/>
</p>

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=SaarthakG-Dtu&layout=compact&theme=tokyonight&hide_border=true"/>
</p>

---

# ğŸ“ Education

ğŸ“ B.Tech â€” Mathematics & Computing
ğŸ“ Delhi Technological University (DTU)

---

# ğŸ¯ Current Focus

ğŸ§  Strengthening fundamentals in Deep Learning & Mathematical Foundations
ğŸ‘ï¸ Advancing in Computer Vision & Multimodal AI
ğŸ“š Preparing for AI Research Internships & MS in AI / Robotics
ğŸ”¬ Exploring perception, reasoning, and world modelling systems

---

# ğŸŒ Connect

ğŸ“§ Email: [saarthakgupta2006@gmail.com](mailto:saarthakgupta2006@gmail.com)
ğŸ’» GitHub: https://github.com/SaarthakG-Dtu
ğŸ”— LinkedIn: (Add your LinkedIn URL)

---

<p align="center">
âœ¨ Curious about intelligence. Focused on perception. Aiming for impactful AI research. âœ¨
</p>
